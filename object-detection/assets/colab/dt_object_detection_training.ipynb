{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mIJd6b6pbsk"
      },
      "source": [
        "# First, let us set up a few dependencies\n",
        "\n",
        "Don't forget to switch to a GPU-enabled colab runtime!\n",
        "\n",
        "```\n",
        "Runtime -> Change Runtime Type -> GPU\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E2APl4pnbAa"
      },
      "source": [
        "import os\n",
        "import contextlib\n",
        "@contextlib.contextmanager\n",
        "def directory(name):\n",
        "  ret = os.getcwd()\n",
        "  os.chdir(name)\n",
        "  yield None\n",
        "  os.chdir(ret)\n",
        "\n",
        "import subprocess\n",
        "def run(input, exception_on_failure=False):\n",
        "  try:\n",
        "    program_output = subprocess.check_output(f\"{input}\", shell=True, universal_newlines=True, stderr=subprocess.STDOUT)\n",
        "  except Exception as e:\n",
        "    if exception_on_failure:\n",
        "      raise e\n",
        "    program_output = e.output\n",
        "\n",
        "    return program_output\n",
        "def prun(input, exception_on_failure=False):\n",
        "  x = run(input, exception_on_failure)\n",
        "  print(x)\n",
        "  return x"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6gJLjcipgNw"
      },
      "source": [
        "# This mounts your google drive to this notebook. You might have to change the path to fit with your dataset folder inside your drive.\n",
        "\n",
        "Read the instruction output by the cell bellow carefully!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a temporary workspace\n",
        "import tempfile\n",
        "\n",
        "\n",
        "SESSION_WORKSPACE = tempfile.mkdtemp()\n",
        "print(f\"Session workspace created at: {SESSION_WORKSPACE}\")"
      ],
      "metadata": {
        "id": "shRmyOAbatwZ",
        "outputId": "405b51d0-89dc-4f37-9805-7e2096c7945b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Session workspace created at: /tmp/tmpesliwgsd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "DRIVE_PATH = \"/content/drive/My Drive\""
      ],
      "metadata": {
        "id": "Iod0c4KF_Vxo",
        "outputId": "6a00c5d7-27cd-46c5-935b-037b93f4887d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the dataset\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "\n",
        "DATASET_DIR_NAME = \"duckietown_object_detection_dataset\"\n",
        "DATASET_ZIP_NAME = f\"{DATASET_DIR_NAME}.zip\"\n",
        "DATASET_DIR_PATH = os.path.join(SESSION_WORKSPACE, DATASET_DIR_NAME)\n",
        "TRAIN_DIR = \"train\"\n",
        "VALIDATION_DIR = \"val\"\n",
        "IMAGES_DIR = \"images\"\n",
        "LABELS_DIR = \"labels\"\n",
        "\n",
        "\n",
        "def show_info(base_path: str):\n",
        "  for l1 in [TRAIN_DIR, VALIDATION_DIR]:\n",
        "    for l2 in [IMAGES_DIR, LABELS_DIR]:\n",
        "      p = os.path.join(base_path, l1, l2)\n",
        "      print(f\"#Files in {l1}/{l2}: {len(os.listdir(p))}\")\n",
        "\n",
        "\n",
        "def unzip_dataset():\n",
        "  # check zipped file\n",
        "  zip_path = os.path.join(DRIVE_PATH, DATASET_ZIP_NAME)\n",
        "  assert os.path.exists(zip_path), f\"No zipped dataset found at {zip_path}! Abort!\"\n",
        "\n",
        "  # unzip the data\n",
        "  print(\"Unpacking zipped data...\")\n",
        "  shutil.unpack_archive(zip_path, DATASET_DIR_PATH)\n",
        "  print(f\"Zipped dataset unpacked to {DATASET_DIR_PATH}\")\n",
        "\n",
        "  # show some info\n",
        "  show_info(DATASET_DIR_PATH)\n",
        "\n",
        "\n",
        "unzip_dataset()"
      ],
      "metadata": {
        "id": "qhdlb1osbf_a",
        "outputId": "3b5cb875-ae20-4d94-b913-4692520b17be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unpacking zipped data...\n",
            "Zipped dataset unpacked to /tmp/tmpesliwgsd/duckietown_object_detection_dataset\n",
            "#Files in train/images: 804\n",
            "#Files in train/labels: 804\n",
            "#Files in val/images: 202\n",
            "#Files in val/labels: 202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change  working directory to the session workspace\n",
        "os.chdir(SESSION_WORKSPACE)\n",
        "print(f\"PWD: {os.getcwd()}\")\n",
        "\n",
        "# install pytorch and torchvision\n",
        "!pip3 install torch==1.13.0 torchvision==0.14.0"
      ],
      "metadata": {
        "id": "xpWozMbUeFZA",
        "outputId": "0957f931-275f-4093-d1c8-afb442d03132",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PWD: /tmp/tmpesliwgsd\n",
            "Collecting torch==1.13.0\n",
            "  Downloading torch-1.13.0-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.15.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchvision==0.14.0 (from versions: 0.15.1, 0.15.2, 0.16.0, 0.16.1, 0.16.2, 0.17.0, 0.17.1, 0.17.2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 0.20.0, 0.20.1, 0.21.0, 0.22.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchvision==0.14.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc4VMcwmpr84"
      },
      "source": [
        "# Next, we will clone Yolov5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8L68QAeZF9G",
        "outputId": "391bd0c0-01b5-4e64-f025-5cf8595b5e8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!rm -rf ./yolov5\n",
        "!git clone https://github.com/ultralytics/yolov5.git -b v7.0\n",
        "!cd yolov5 && pip3 install -r requirements.txt"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 17413, done.\u001b[K\n",
            "remote: Counting objects: 100% (86/86), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 17413 (delta 64), reused 22 (delta 22), pack-reused 17327 (from 4)\u001b[K\n",
            "Receiving objects: 100% (17413/17413), 16.30 MiB | 20.31 MiB/s, done.\n",
            "Resolving deltas: 100% (11935/11935), done.\n",
            "Note: switching to '915bbf294bb74c859f0b41f1c23bc395014ea679'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.1.44)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (7.34.0)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (4.11.0.86)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (11.2.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (1.15.2)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (4.67.1)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (2.18.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython->-r requirements.txt (line 5)) (4.0.12)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (2.9.0.post0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.0->-r requirements.txt (line 16)) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (3.8)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (5.29.4)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (3.1.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython->-r requirements.txt (line 5)) (5.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->-r requirements.txt (line 6)) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->-r requirements.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 6)) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 22)) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We now inform the training process of the format and location of our dataset"
      ],
      "metadata": {
        "id": "g5iilV-e76YN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ./yolov5/data/duckietown.yaml\n",
        "\n",
        "# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]\n",
        "train: ../duckietown_object_detection_dataset/train\n",
        "val: ../duckietown_object_detection_dataset/val\n",
        "\n",
        "# number of classes\n",
        "nc: 4\n",
        "\n",
        "# class names\n",
        "names: [ 'duckie', 'cone', 'truck', 'bus' ]"
      ],
      "metadata": {
        "id": "7u3D124u8Flw",
        "outputId": "c8f18d47-bf21-4013-f03a-bd9a6f1a9f25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ./yolov5/data/duckietown.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CalmQI9Ypx5v"
      },
      "source": [
        "# And we're ready to train! This step will take about 5 minutes.\n",
        "\n",
        "Notice that we're only training for 10 epochs. That's probably not enough!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kss7Oid6OkAv",
        "outputId": "4942be15-0025-444b-de22-afbc7fc6a9bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!cd yolov5 && python3 train.py --cfg ./models/yolov5n.yaml --img 416 --batch 32 --epochs 10 --data duckietown.yaml --weights yolov5n.pt"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-07 09:08:02.588394: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746608882.608459    4228 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746608882.614937    4228 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-07 09:08:02.636902: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5n.pt, cfg=./models/yolov5n.yaml, data=duckietown.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=32, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 416 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/tmpesliwgsd/yolov5/train.py\", line 633, in <module>\n",
            "    main(opt)\n",
            "  File \"/tmp/tmpesliwgsd/yolov5/train.py\", line 502, in main\n",
            "    check_file(opt.data), check_yaml(opt.cfg), check_yaml(opt.hyp), str(opt.weights), str(opt.project)  # checks\n",
            "    ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/tmpesliwgsd/yolov5/utils/general.py\", line 483, in check_file\n",
            "    assert len(files), f'File not found: {file}'  # assert file was found\n",
            "           ^^^^^^^^^^\n",
            "AssertionError: File not found: duckietown.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "all_exps = os.listdir(\"yolov5/runs/train\")\n",
        "all_exps_filtered = map(lambda x: int(x.replace(\"exp\", \"1\")), filter(lambda x: x.startswith(\"exp\"), all_exps))\n",
        "all_exps_filtered = np.array(list(all_exps))\n",
        "latest_exp_index = np.argmax(all_exps)\n",
        "latest_exp = all_exps[latest_exp_index]\n",
        "print(f\"Latest exp is {latest_exp}\")\n",
        "\n",
        "prun(f\"cp yolov5/runs/train/{latest_exp}/weights/best.pt yolov5/best.pt\")\n",
        "print(f\"Marked the model from the latest run ({latest_exp}) as yolov5/best.pt.\")"
      ],
      "metadata": {
        "id": "b5jSQ4XubFqH",
        "outputId": "b67ada79-0dd2-4783-936e-b8796d4e01c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latest exp is exp\n",
            "cp: cannot stat 'yolov5/runs/train/exp/weights/best.pt': No such file or directory\n",
            "\n",
            "Marked the model from the latest run (exp) as yolov5/best.pt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz2PZ7d0qPt0"
      },
      "source": [
        "# Next, we can upload your model to Duckietown's cloud!\n",
        "\n",
        "We will need our token to access our personal cloud space."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Fill in the duckietown token here\n",
        "YOUR_DT_TOKEN = \"dt1-HeFLq6vDkJmSLHH1txvYgYLYBVWhq2NPkpT6k-43dzqWFnWd8KBa1yev1g3UKnzVxZkkTbfaVLa8CvtvbYodXK1yuNcFH4VEgrERoS7R\""
      ],
      "metadata": {
        "id": "hl-HhnrFtKnp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we chose the location of the trained model on disk and its name once uploaded to our cloud space. You should not change these values, or the robots will not be able to find the model to download."
      ],
      "metadata": {
        "id": "PCd7RrjLc64Z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bNXEgAFpRIH",
        "outputId": "86f803cc-272c-412f-d8d1-cfb1607015d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, './yolov5')\n",
        "\n",
        "# DO NOT CHANGE THESE\n",
        "model_name = \"yolov5n\"\n",
        "model_local_path = \"./yolov5/best.pt\"\n",
        "model_remote_path = f\"courses/mooc/objdet/data/nn_models/{model_name}.pt\"\n",
        "\n",
        "# install DCSS client\n",
        "!pip3 install dt-data-api"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dt-data-api\n",
            "  Downloading dt-data-api-2.1.0.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from dt-data-api) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from dt-data-api) (4.13.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from dt-data-api) (5.4.0)\n",
            "Collecting dt-authentication (from dt-data-api)\n",
            "  Downloading dt-authentication-2.2.0.tar.gz (9.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->dt-data-api) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->dt-data-api) (4.13.2)\n",
            "Collecting base58 (from dt-authentication->dt-data-api)\n",
            "  Downloading base58-2.1.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting ecdsa (from dt-authentication->dt-data-api)\n",
            "  Downloading ecdsa-0.19.1-py2.py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->dt-data-api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->dt-data-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->dt-data-api) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->dt-data-api) (2025.4.26)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from ecdsa->dt-authentication->dt-data-api) (1.17.0)\n",
            "Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
            "Downloading ecdsa-0.19.1-py2.py3-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.6/150.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: dt-data-api, dt-authentication\n",
            "  Building wheel for dt-data-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dt-data-api: filename=dt_data_api-2.1.0-py3-none-any.whl size=14363 sha256=4a3a0df5a64fdfcf8327acdb84296f7d8f24e2c41a853f9b41e63ec0beaddca9\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/b5/60/d35f7f09040a1b33db975be4f28603b344bf1e9d2bddef6ac7\n",
            "  Building wheel for dt-authentication (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dt-authentication: filename=dt_authentication-2.2.0-py3-none-any.whl size=10095 sha256=de1c21b8ff50215f38173b0e45980de76ef70428a1cd578fab541614e0bb03aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/d5/e7/985e33386d61f6b4027fe7f9a2afec5a491972b3948b71a425\n",
            "Successfully built dt-data-api dt-authentication\n",
            "Installing collected packages: ecdsa, base58, dt-authentication, dt-data-api\n",
            "Successfully installed base58-2.1.1 dt-authentication-2.2.0 dt-data-api-2.1.0 ecdsa-0.19.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now open a pointer to our cloud space and upload the model."
      ],
      "metadata": {
        "id": "B8DYodvDdQKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from dt_data_api import DataClient, Storage\n",
        "\n",
        "# open a pointer to our personal duckietown cloud space\n",
        "client = DataClient(YOUR_DT_TOKEN)\n",
        "storage = client.storage(\"user\")\n",
        "\n",
        "# upload model\n",
        "upload = storage.upload(model_local_path, model_remote_path)\n",
        "upload.join()"
      ],
      "metadata": {
        "id": "NAU4dTNJVkyx",
        "outputId": "8340f243-0d73-46bd-d631-87c851fdd3cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The file /tmp/tmpesliwgsd/yolov5/best.pt does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-8a773fbdffef>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# upload model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mupload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_local_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_remote_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mupload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dt_data_api/storage.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(self, source, destination, length)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The file {file_path} does not exist.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0msource_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The file /tmp/tmpesliwgsd/yolov5/best.pt does not exist."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUVJ5BfBGq7F"
      },
      "source": [
        "# Done!\n",
        "\n",
        "We're done training! You can now close this tab and go back to the `Training` notebook"
      ]
    }
  ]
}